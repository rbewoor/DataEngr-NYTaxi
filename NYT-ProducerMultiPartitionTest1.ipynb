{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StartTime is: Sun Jan  6 12:21:38 2019\n",
      "Skipped row as Error during PU date assignment for row=2\n",
      "Processing csv row number 500000\n",
      "Sent 500276 row as the 500000 th message to Kafka\n",
      "Processing csv row number 1000000\n",
      "Sent 1000277 row as the 1000000 th message to Kafka\n",
      "Processing csv row number 1500000\n",
      "Sent 1500277 row as the 1500000 th message to Kafka\n",
      "Processing csv row number 2000000\n",
      "Sent 2000278 row as the 2000000 th message to Kafka\n",
      "Processing csv row number 2500000\n",
      "Sent 2500291 row as the 2500000 th message to Kafka\n",
      "Processing csv row number 3000000\n",
      "Sent 3000334 row as the 3000000 th message to Kafka\n",
      "Processing csv row number 3500000\n",
      "Sent 3500336 row as the 3500000 th message to Kafka\n",
      "Processing csv row number 4000000\n",
      "Sent 4000386 row as the 4000000 th message to Kafka\n",
      "Processing csv row number 4500000\n",
      "Sent 4500403 row as the 4500000 th message to Kafka\n",
      "Processing csv row number 5000000\n",
      "Sent 5000417 row as the 5000000 th message to Kafka\n",
      "Processing csv row number 5500000\n",
      "Sent 5500420 row as the 5500000 th message to Kafka\n",
      "Processing csv row number 6000000\n",
      "Sent 6000422 row as the 6000000 th message to Kafka\n",
      "Processing csv row number 6500000\n",
      "Sent 6500423 row as the 6500000 th message to Kafka\n",
      "Processing csv row number 7000000\n",
      "Processing csv row number 7500000\n",
      "Processing csv row number 8000000\n",
      "Processing csv row number 8500000\n",
      "\n",
      "\n",
      "Processed 8713832 rows from csv\n",
      "Sent 6999708 messages to Kafka\n",
      "NOT SENT 1714123 rows as OB\n",
      "\n",
      "EndTime is: Sun Jan  6 12:46:50 2019\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jan  6 11:38:51 2019\n",
    "\n",
    "@author: RB\n",
    "\"\"\"\n",
    "from kafka import KafkaProducer\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "\n",
    "print('\\nStartTime is:',datetime.now().strftime(\"%c\"))\n",
    "fileLocation = r'C:\\Everything\\01SRH-BDBA Acads\\Blk2-DataEngr\\NYTaxi\\testingData\\yellow_tripdata_2018-06-full.csv'\n",
    "topicName = 'TestNYTFullJuneDb10'\n",
    "producer = KafkaProducer(bootstrap_servers='localhost:9092')\n",
    "maxRows2Read = 10000000                            # Specify the maximum number of rows to read from the csv\n",
    "rowsReadcount = 0\n",
    "countSent2Producer = 0\n",
    "boundMatchRowsCount = 0\n",
    "boundNotMatchRowsCount = 0\n",
    "boundLowerPUDatetime = '2018-06-01 00:00:00'   # the pickup datetime from csv to be greater or equal to this\n",
    "boundUpperPUDatetime = '2018-06-25 00:00:00'   # the pickup datetime from csv to be lower than this\n",
    "\n",
    "with open(fileLocation, \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=\",\")\n",
    "    for row in csv_reader:\n",
    "        rowsReadcount = rowsReadcount + 1\n",
    "        if rowsReadcount % 500000 == 0:    \n",
    "            print(f'Processing csv row number {rowsReadcount}')\n",
    "        if rowsReadcount == (maxRows2Read + 1):\n",
    "            print('Reached rows to read limit set by user')\n",
    "#            print('Reached limit for first 24 hours and exiting last entry should have PickUp time of 01-06-2018  23:43:00')\n",
    "            break\n",
    "        try:\n",
    "            row_tpep_pickup_datetime = row[1]\n",
    "        except:\n",
    "            print(f'Skipped row as Error during PU date assignment for row={rowsReadcount}')\n",
    "            continue\n",
    "#        print(f'row_tpep_pickup_datetime={row_tpep_pickup_datetime}')\n",
    "        if (row_tpep_pickup_datetime < boundUpperPUDatetime and row_tpep_pickup_datetime >= boundLowerPUDatetime):\n",
    "            joinedRow = ','.join(row)\n",
    "            producer.send(topicName, joinedRow.encode('utf-8'))\n",
    "            countSent2Producer = countSent2Producer + 1\n",
    "            if countSent2Producer % 500000 == 0:\n",
    "                print(f'Sent {rowsReadcount} row as the {countSent2Producer} th message to Kafka')\n",
    "        elif not (row[0] == 'VendorID'):\n",
    "#            print(f'Row {rowsReadcount} not sent to producer, row PUDatetime={row_tpep_pickup_datetime} and outside bounds')\n",
    "            boundNotMatchRowsCount = boundNotMatchRowsCount + 1\n",
    "# =============================================================================\n",
    "#         if rowsReadcount % 50000 == 0:\n",
    "#             print(f'Row={rowsReadcount}, Contents are:::\\n{joinedRow}' )\n",
    "#             print(f'Processed the {rowsReadcount} th row of csv and sent to Kafka' )\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nProcessed %d rows from csv\\nSent %d messages to Kafka\\nNOT SENT %d rows as OB\" %(rowsReadcount-1, countSent2Producer, boundNotMatchRowsCount))\n",
    "print('\\nEndTime is:',datetime.now().strftime(\"%c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
